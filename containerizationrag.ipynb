{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72f3cc87-f8c1-498b-9007-cc999574b84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (4.1.0)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.31.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (69.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ehazizi\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.7.4)\n",
      "Downloading sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "   ---------------------------------------- 0.0/470.2 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/470.2 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/470.2 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/470.2 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/470.2 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 30.7/470.2 kB 108.9 kB/s eta 0:00:05\n",
      "   -- ------------------------------------ 30.7/470.2 kB 108.9 kB/s eta 0:00:05\n",
      "   -- ------------------------------------ 30.7/470.2 kB 108.9 kB/s eta 0:00:05\n",
      "   -- ------------------------------------ 30.7/470.2 kB 108.9 kB/s eta 0:00:05\n",
      "   --- ------------------------------------ 41.0/470.2 kB 81.9 kB/s eta 0:00:06\n",
      "   ----- --------------------------------- 61.4/470.2 kB 126.1 kB/s eta 0:00:04\n",
      "   ----- --------------------------------- 71.7/470.2 kB 135.6 kB/s eta 0:00:03\n",
      "   ----- --------------------------------- 71.7/470.2 kB 135.6 kB/s eta 0:00:03\n",
      "   ------- ------------------------------- 92.2/470.2 kB 145.5 kB/s eta 0:00:03\n",
      "   ------- ------------------------------- 92.2/470.2 kB 145.5 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 112.6/470.2 kB 159.8 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 112.6/470.2 kB 159.8 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 112.6/470.2 kB 159.8 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 112.6/470.2 kB 159.8 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 112.6/470.2 kB 159.8 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 112.6/470.2 kB 159.8 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 112.6/470.2 kB 159.8 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 112.6/470.2 kB 159.8 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 112.6/470.2 kB 159.8 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 112.6/470.2 kB 159.8 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 112.6/470.2 kB 159.8 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 112.6/470.2 kB 159.8 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 112.6/470.2 kB 159.8 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 112.6/470.2 kB 159.8 kB/s eta 0:00:03\n",
      "   --------- ---------------------------- 112.6/470.2 kB 159.8 kB/s eta 0:00:03\n",
      "   ---------- ---------------------------- 122.9/470.2 kB 82.8 kB/s eta 0:00:05\n",
      "   ---------- ---------------------------- 122.9/470.2 kB 82.8 kB/s eta 0:00:05\n",
      "   ----------- --------------------------- 143.4/470.2 kB 92.6 kB/s eta 0:00:04\n",
      "   ------------ -------------------------- 153.6/470.2 kB 94.6 kB/s eta 0:00:04\n",
      "   ------------ -------------------------- 153.6/470.2 kB 94.6 kB/s eta 0:00:04\n",
      "   ------------ -------------------------- 153.6/470.2 kB 94.6 kB/s eta 0:00:04\n",
      "   ------------ -------------------------- 153.6/470.2 kB 94.6 kB/s eta 0:00:04\n",
      "   ------------ -------------------------- 153.6/470.2 kB 94.6 kB/s eta 0:00:04\n",
      "   ------------ -------------------------- 153.6/470.2 kB 94.6 kB/s eta 0:00:04\n",
      "   ------------ -------------------------- 153.6/470.2 kB 94.6 kB/s eta 0:00:04\n",
      "   ------------ -------------------------- 153.6/470.2 kB 94.6 kB/s eta 0:00:04\n",
      "   ------------ -------------------------- 153.6/470.2 kB 94.6 kB/s eta 0:00:04\n",
      "   ------------ -------------------------- 153.6/470.2 kB 94.6 kB/s eta 0:00:04\n",
      "   ------------ -------------------------- 153.6/470.2 kB 94.6 kB/s eta 0:00:04\n",
      "   -------------- ------------------------ 174.1/470.2 kB 80.7 kB/s eta 0:00:04\n",
      "   -------------- ------------------------ 174.1/470.2 kB 80.7 kB/s eta 0:00:04\n",
      "   -------------- ------------------------ 174.1/470.2 kB 80.7 kB/s eta 0:00:04\n",
      "   ---------------- ---------------------- 194.6/470.2 kB 86.1 kB/s eta 0:00:04\n",
      "   ---------------- ---------------------- 204.8/470.2 kB 88.3 kB/s eta 0:00:04\n",
      "   ---------------- ---------------------- 204.8/470.2 kB 88.3 kB/s eta 0:00:04\n",
      "   ------------------ -------------------- 225.3/470.2 kB 93.6 kB/s eta 0:00:03\n",
      "   ------------------- ------------------- 235.5/470.2 kB 95.5 kB/s eta 0:00:03\n",
      "   -------------------- ----------------- 256.0/470.2 kB 102.1 kB/s eta 0:00:03\n",
      "   -------------------- ----------------- 256.0/470.2 kB 102.1 kB/s eta 0:00:03\n",
      "   ---------------------- --------------- 276.5/470.2 kB 107.1 kB/s eta 0:00:02\n",
      "   ---------------------- --------------- 276.5/470.2 kB 107.1 kB/s eta 0:00:02\n",
      "   ----------------------- -------------- 286.7/470.2 kB 106.6 kB/s eta 0:00:02\n",
      "   ------------------------ ------------- 307.2/470.2 kB 113.8 kB/s eta 0:00:02\n",
      "   --------------------------- ---------- 337.9/470.2 kB 122.6 kB/s eta 0:00:02\n",
      "   --------------------------- ---------- 337.9/470.2 kB 122.6 kB/s eta 0:00:02\n",
      "   --------------------------- ---------- 337.9/470.2 kB 122.6 kB/s eta 0:00:02\n",
      "   --------------------------- ---------- 337.9/470.2 kB 122.6 kB/s eta 0:00:02\n",
      "   --------------------------- ---------- 337.9/470.2 kB 122.6 kB/s eta 0:00:02\n",
      "   --------------------------- ---------- 337.9/470.2 kB 122.6 kB/s eta 0:00:02\n",
      "   ----------------------------- -------- 368.6/470.2 kB 121.4 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 399.4/470.2 kB 129.7 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 399.4/470.2 kB 129.7 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 419.8/470.2 kB 132.4 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 440.3/470.2 kB 137.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 440.3/470.2 kB 137.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 440.3/470.2 kB 137.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 440.3/470.2 kB 137.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 440.3/470.2 kB 137.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 440.3/470.2 kB 137.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 440.3/470.2 kB 137.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 440.3/470.2 kB 137.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 440.3/470.2 kB 137.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 440.3/470.2 kB 137.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 440.3/470.2 kB 137.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 450.6/470.2 kB 119.9 kB/s eta 0:00:01\n",
      "   --------------------------------------  460.8/470.2 kB 68.7 kB/s eta 0:00:01\n",
      "   --------------------------------------- 470.2/470.2 kB 69.8 kB/s eta 0:00:00\n",
      "Installing collected packages: sentence-transformers\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 4.1.0\n",
      "    Uninstalling sentence-transformers-4.1.0:\n",
      "      Successfully uninstalled sentence-transformers-4.1.0\n",
      "Successfully installed sentence-transformers-5.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f01446f3-54f1-4cc5-8f13-1270b3072133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b7a861a38c4192b5d452cf9e0bcb3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Vector store built and saved to vector_store.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv(\"containerization.csv\")\n",
    "\n",
    "# Step 2: Combine relevant columns into a single context string per row\n",
    "def build_context(row):\n",
    "    return (\n",
    "        f\"Paper ID: {row['paperid']}\\n\"\n",
    "        f\"Title: {row['title']}\\n\"\n",
    "        f\"Tools: {row['tools']}\\n\"\n",
    "        f\"DevOps Phase: {row['devopsphase']}\\n\"\n",
    "        f\"Challenge: {row['challenge']}\\n\"\n",
    "        f\"Theme: {row['theme']}\\n\"\n",
    "        f\"Contribution Type: {row['contributiontype']}\"\n",
    "    )\n",
    "\n",
    "df[\"context\"] = df.apply(build_context, axis=1)\n",
    "\n",
    "# Step 3: Encode the context with a sentence transformer\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = model.encode(df[\"context\"].tolist(), show_progress_bar=True)\n",
    "\n",
    "# Step 4: Save the vector store\n",
    "with open(\"vector_store.pkl\", \"wb\") as f:\n",
    "    pickle.dump((df, embeddings), f)\n",
    "\n",
    "print(\"âœ… Vector store built and saved to vector_store.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23d19ece-2b78-43e8-901e-ca78e6968467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "\n",
    "# Load vector store\n",
    "with open(\"vector_store.pkl\", \"rb\") as f:\n",
    "    df, embeddings = pickle.load(f)\n",
    "\n",
    "# Load embedding model (same as used in vector store creation)\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Set OpenAI API key securely\n",
    "openai.api_key = \"Your_OpenAI_Key\"  # Replace with your actual key or use os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the RAG-based recommendation function\n",
    "def recommend_with_rag(query, top_k=5):\n",
    "    # Step 1: Embed user query\n",
    "    query_embedding = model.encode([query])\n",
    "\n",
    "    # Step 2: Compute cosine similarities\n",
    "    similarities = cosine_similarity(query_embedding, embeddings)[0]\n",
    "    top_indices = similarities.argsort()[::-1][:top_k]\n",
    "\n",
    "    # Step 3: Embed paper IDs into the context to make them visible to the model\n",
    "    retrieved = \"\\n\\n---\\n\\n\".join(\n",
    "        f\"Paper ID: {df.iloc[i]['paperid']}\\n{df.iloc[i]['context']}\" for i in top_indices\n",
    "    )\n",
    "\n",
    "    # Step 4: Prompt\n",
    "    prompt = f\"\"\"You are a helpful DevOps assistant.\n",
    "The user is interested in: \"{query}\"\n",
    "\n",
    "Based on the following relevant papers and contexts, recommend:\n",
    "- Tools (e.g., Docker, Helm)\n",
    "- DevOps practices\n",
    "- Platform and configuration advice\n",
    "\n",
    "Important:\n",
    "- In your answer, cite the source of each recommendation.\n",
    "- When citing a single paper, use this format: (Reference 147)\n",
    "- When citing multiple, use: (References 147, 589, 785)\n",
    "\n",
    "Relevant contexts:\n",
    "{retrieved}\n",
    "\n",
    "Respond with a clear recommendation. Use the reference format shown above.\n",
    "\"\"\"\n",
    "\n",
    "    # Step 5: OpenAI ChatCompletion call\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful DevOps assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1c37546-6171-4dbe-95b0-57a6d01549c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ðŸ’¬ Enter your DevOps or Kubernetes-related question:  orchestration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¢ Recommendation:\n",
      "\n",
      "Based on the given research papers, here are the recommendations:\n",
      "\n",
      "Tools:\n",
      "1. Kubernetes: This is by far the most heavily suggested tool for orchestration in the literature (References 912, 1007, 988). Kubernetes allows for automated deployment, scaling, and management of containerized applications.\n",
      "2. Docker: As a platform for operating-system-level virtualization, Docker packages applications and their dependencies in containers, enabling applications to run smoothly in various computing environments (References 912,1007,948).\n",
      "3. Helm: A package manager for Kubernetes, Helm simplifies deployment of applications on Kubernetes and represents a considerable boon for DevOps processes (Reference 912).\n",
      "4. ArgoCD: Mentioned in two papers, ArgoCD provides declarative and version-controlled application deployment to Kubernetes (References 912, 948)\n",
      "\n",
      "DevOps Practices:\n",
      "1. DevOps phases such as Deployment, Orchestration, and Configuration Management were highlighted (References 912, 1007, 988, 948).\n",
      "2. GitOps for Runtime Orchestration: This practice combines Git, the straightforward version control system, with Kubernetes, providing a way to implement Continuous Deployment for cloud native applications (Reference 912).\n",
      "3. Utilize Automated Testing in Container Orchestration: Automated testing in continuous integration and delivery process increases the effectiveness of the overall DevOps pipeline (Reference 948)\n",
      "4. Security Framework: Setting appropriate policies with the help of tools such as Open Policy Agent in Kubernetes environments can manage vulnerabilities in orchestration layers (Reference 1007)\n",
      "\n",
      "Platform and Configuration Advice:\n",
      "1. OpenStack can be considered if one is leaning towards orchestrating multi-site deployments. It is used along with Terraform and Ansible (Reference 332).\n",
      "2. Use AI-Driven Orchestration for automating cluster operations and resource optimization in Kubernetes environment (Reference 988).\n",
      "3. Lastly, for securing Kubernetes environments, Open Policy Agent can be used for policy enforcement (Reference 1007).\n"
     ]
    }
   ],
   "source": [
    "# Ask user for input query\n",
    "user_query = input(\"ðŸ’¬ Enter your DevOps or Kubernetes-related question: \")\n",
    "\n",
    "# Generate recommendation using RAG\n",
    "recommendation = recommend_with_rag(user_query)\n",
    "\n",
    "# Print the result\n",
    "print(\"ðŸ“¢ Recommendation:\\n\")\n",
    "print(recommendation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcad0a4c-a78d-4fea-8d23-7a9a85054da1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
